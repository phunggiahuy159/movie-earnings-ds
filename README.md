# üé¨ Box Office Prediction - ML Pipeline

End-to-end machine learning pipeline for predicting movie box office revenue using IMDb data.

## üìã Features

- **Data Crawling**: Scrape movie data from IMDb (17 fields including budget, cast, crew, ratings, worldwide gross)
- **Data Cleaning**: Automated preprocessing and feature engineering
- **EDA Visualizations**: Comprehensive exploratory analysis with 6+ interactive plots
- **ML Model**: Random Forest model for box office prediction
- **Interactive UI**: Gradio web interface for predictions and visualizations

---

## üöÄ Quick Start

### 1. Create Conda Environment

```bash
conda create -n movie python=3.11 -y
conda activate movie
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Complete Pipeline

```bash
python main.py
```

**This will:**
- Clean and preprocess the data from `dataset/data_joined.csv`
- Extract features (budget, runtime, ratings, cast/crew counts, genres, etc.)
- Train Random Forest model
- Generate evaluation metrics (R¬≤, MAE, RMSE)
- Create 6 EDA visualizations and save to `demo/plots/`
- Save trained model to `models/box_office_model.pkl`
- Save cleaned data to `dataset/data_cleaned.csv`

### 4. Launch Gradio Web Interface

```bash
python src/gradio_app.py
```

Open your browser to: **http://localhost:7860**

---

## üéØ Using the Gradio Interface

The web app has 4 main tabs:

### üéØ Make Prediction
- Enter movie details (budget, runtime, rating, cast count, genre, etc.)
- Click "Predict Box Office Gross"
- Get predicted worldwide revenue, ROI, and profit estimation

### üìä Exploratory Analysis
- View interactive visualizations:
  - Gross revenue distribution
  - Budget vs Gross correlation
  - Genre performance analysis
  - Rating analysis
  - And more...

### üìà Model Performance
- View model metrics (R¬≤, MAE, RMSE)
- See feature importance ranking
- Correlation heatmap

### ‚ÑπÔ∏è Dataset Info
- Dataset statistics
- Sample movie data
- Feature descriptions

---

## üìÅ Project Structure

```
bor-prediction-analysis/
‚îú‚îÄ‚îÄ main.py                          # Main pipeline runner
‚îú‚îÄ‚îÄ RUN.sh                           # Automated setup script
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îú‚îÄ‚îÄ README.md                        # This file
‚îú‚îÄ‚îÄ QUICKSTART.md                    # Quick reference guide
‚îÇ
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ data_joined.csv              # Raw IMDb data (26+ movies)
‚îÇ   ‚îî‚îÄ‚îÄ data_cleaned.csv             # Cleaned data (generated by pipeline)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ box_office_model.pkl         # Trained Random Forest model (generated)
‚îÇ
‚îú‚îÄ‚îÄ demo/
‚îÇ   ‚îî‚îÄ‚îÄ plots/                       # EDA visualizations (generated)
‚îÇ       ‚îú‚îÄ‚îÄ gross_distribution.png
‚îÇ       ‚îú‚îÄ‚îÄ budget_vs_gross.png
‚îÇ       ‚îú‚îÄ‚îÄ genre_analysis.png
‚îÇ       ‚îú‚îÄ‚îÄ rating_analysis.png
‚îÇ       ‚îú‚îÄ‚îÄ correlation_heatmap.png
‚îÇ       ‚îî‚îÄ‚îÄ roi_analysis.png
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ pipeline.py                  # Data cleaning + model training
    ‚îú‚îÄ‚îÄ eda_visualizations.py        # EDA plots generation
    ‚îú‚îÄ‚îÄ gradio_app.py                # Interactive web interface
    ‚îú‚îÄ‚îÄ join_data.py                 # Data joining utility
    ‚îî‚îÄ‚îÄ crawler/                     # IMDb web scraper
        ‚îú‚îÄ‚îÄ run_full_crawl.sh        # Crawler script
        ‚îî‚îÄ‚îÄ imdbCrawler/             # Scrapy spider
```

---

## üîß Detailed Usage

### Option 1: Automated Setup (Recommended)

```bash
bash RUN.sh
```

This script will:
1. Create conda environment
2. Install all dependencies
3. Run the complete ML pipeline
4. Display instructions for launching Gradio

### Option 2: Manual Step-by-Step

```bash
# 1. Setup environment
conda create -n movie python=3.11 -y
conda activate movie
pip install -r requirements.txt

# 2. Run pipeline
cd /workspace/bor-prediction-analysis
python main.py

# 3. Launch Gradio
python src/gradio_app.py
```

### Option 3: Run Individual Components

```bash
# Activate environment first
conda activate movie

# Data cleaning and model training only
python src/pipeline.py

# Generate visualizations only
python src/eda_visualizations.py

# Launch Gradio app (requires model to be trained first)
python src/gradio_app.py
```

---

## üï∑Ô∏è Crawling More Data (Optional)

### Crawler Setup (First Time Only)

The crawler uses Playwright for JavaScript rendering. Install the browser:

```bash
# Install Playwright browser binaries
playwright install chromium

# Install system dependencies (Linux only)
playwright install-deps
```

### Running the Crawler

```bash
cd src/crawler
bash run_full_crawl.sh 100   # Crawl 100 movies
bash run_full_crawl.sh 500   # Crawl 500 movies
bash run_full_crawl.sh 1000  # Crawl 1000 movies
```

**Time estimates:**
| Movies | Time       |
|--------|------------|
| 100    | ~2 min     |
| 500    | ~10 min    |
| 1000   | ~20 min    |
| 5000   | ~1-2 hours |

The crawler will:
- Scrape IMDb's most popular movies (sorted by vote count)
- Use Playwright to handle JavaScript pagination ("50 more" button)
- Extract 17 fields per movie
- Save to `dataset/data_joined.csv`

After crawling, re-run the pipeline to retrain with new data:

```bash
cd ../..
python main.py
```

---

## üìä Model Details

### Algorithm
- **Random Forest Regressor** (100 trees, max depth 10)

### Features (12 total)
- Budget, Runtime, IMDb Rating, Rating Count
- Cast Count, Crew Count, Genre Count, Keywords Count
- Languages Count, Countries Count
- Release Year, Primary Genre (encoded)

### Target Variable
- Worldwide Gross Revenue (USD)

### Evaluation Metrics
- R¬≤ Score (coefficient of determination)
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)

### Performance
Typical results on 26-movie dataset:
- Test R¬≤: ~0.75-0.85
- Test MAE: ~$50-100M
- Test RMSE: ~$100-150M

*Performance improves with more data - crawl additional movies!*

---

## üì¶ Requirements

### Python Packages
- pandas >= 2.0.0
- numpy >= 1.24.0
- scikit-learn >= 1.3.0
- matplotlib >= 3.7.0
- seaborn >= 0.12.0
- gradio >= 4.0.0
- scrapy >= 2.11.0 (for crawler)
- scrapy-playwright >= 0.0.40 (for crawler)
- playwright >= 1.40.0 (for crawler)

### System Requirements
- Python 3.11
- Conda (Miniconda or Anaconda)
- 4GB RAM minimum
- Internet connection (for Gradio sharing, optional)

---

## üí° Example Usage

### Making Predictions Programmatically

```python
import pickle
import numpy as np

# Load trained model
with open('models/box_office_model.pkl', 'rb') as f:
    model_data = pickle.load(f)

model = model_data['model']
feature_names = model_data['feature_names']

# Example: Big budget action movie
features = np.array([[
    150000000,  # Budget: $150M
    140,        # Runtime: 140 minutes
    7.8,        # Rating: 7.8/10
    800000,     # Rating Count: 800k votes
    15,         # Cast Count: 15 actors
    20,         # Crew Count: 20 crew members
    3,          # Genre Count: 3 genres
    25,         # Keywords Count: 25 keywords
    2,          # Languages: 2
    1,          # Countries: 1
    2024,       # Release Year: 2024
    0           # Genre: Action (encoded)
]])

predicted_gross = model.predict(features)[0]
print(f"Predicted Worldwide Gross: ${predicted_gross:,.0f}")

# Calculate ROI
budget = 150000000
roi = ((predicted_gross - budget) / budget) * 100
print(f"Expected ROI: {roi:.1f}%")
```

---

## üìà Pipeline Workflow

```
Raw Data (data_joined.csv)
    ‚Üì
[Data Cleaning]
  - Parse monetary values ($XXX,XXX,XXX)
  - Extract runtime from strings
  - Convert ratings to numeric
  - Extract year from dates
    ‚Üì
[Feature Engineering]
  - Count cast/crew/genres/keywords
  - Extract primary genre
  - Calculate ROI
  - Encode categorical variables
    ‚Üì
[Model Training]
  - Train/test split (80/20)
  - Random Forest training
  - Model evaluation
    ‚Üì
[Save Outputs]
  - models/box_office_model.pkl
  - dataset/data_cleaned.csv
    ‚Üì
[EDA Generation]
  - 6 visualization plots
  - demo/plots/*.png
    ‚Üì
[Gradio Interface]
  - Interactive predictions
  - Live visualizations
  - Model metrics display
```

---

## üéì Dataset Information

### Data Fields (17 total)
- **Movie_ID**: IMDb ID (e.g., tt0468569)
- **Movie_Title**: Film title
- **Budget**: Production budget (USD)
- **Gross_worldwide**: Total worldwide box office (USD)
- **Runtime**: Duration in minutes
- **Rating**: IMDb rating (0-10)
- **Rating_Count**: Number of user ratings
- **Cast**: Comma-separated actor names
- **Crew**: Comma-separated crew names
- **Studios**: Production companies
- **Genre**: Comma-separated genres
- **Keywords**: Comma-separated keywords
- **Languages**: Comma-separated languages
- **Countries**: Comma-separated countries
- **Filming_Location**: Shooting locations
- **Release_Data**: Release date
- **ListOfCertificate**: Age ratings (e.g., PG-13, R)

### Current Dataset
- **26 movies** (can be expanded via crawler)
- Sourced from IMDb's most popular movies
- All fields populated with real data

---

## üêõ Troubleshooting

### Environment Issues
```bash
# Reset environment
conda deactivate
conda remove -n movie --all -y
conda create -n movie python=3.11 -y
conda activate movie
pip install -r requirements.txt
```

### Module Not Found
```bash
# Ensure you're in the project directory
cd /workspace/bor-prediction-analysis

# Reinstall packages
pip install -r requirements.txt --upgrade
```

### Gradio Won't Start
```bash
# Check if model exists
ls models/box_office_model.pkl

# If missing, run pipeline first
python main.py

# Then launch Gradio
python src/gradio_app.py
```

### Port Already in Use
```bash
# Change port in src/gradio_app.py line 324:
# interface.launch(share=False, server_name="0.0.0.0", server_port=7861)
```

---

## üìù Notes

- Model trained on limited dataset (26 movies) - performance improves with more data
- Crawl additional movies to enhance predictions
- Budget and gross values must be in USD
- All monetary values are in absolute dollars (not millions)
- Model works best for mainstream Hollywood productions

---

## ü§ù Contributing

To add more data:
1. Run crawler: `cd src/crawler && bash run_full_crawl.sh 500`
2. Retrain model: `cd ../.. && python main.py`
3. Test predictions: `python src/gradio_app.py`

---

## üìÑ License

This project is for educational purposes.

---

## üéâ Credits

- **Data Source**: IMDb
- **ML Framework**: scikit-learn
- **Web Framework**: Gradio
- **Scraping**: Scrapy

---

**Happy Predicting! üé¨üìä**
